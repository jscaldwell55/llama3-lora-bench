{
  "config": {
    "dataset": {
      "max_samples": 500
    },
    "lora": {
      "lora_alpha": 32,
      "lora_dropout": 0.05,
      "r": 32,
      "target_modules": [
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj"
      ]
    },
    "name": "large_r32",
    "training": {
      "batch_size": 4,
      "gradient_accumulation_steps": 2,
      "learning_rate": "3e-4",
      "num_epochs": 1,
      "warmup_steps": 20
    }
  },
  "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
  "start_time": "2025-07-04T22:10:57.476436",
  "model_load_time": 3.219106435775757,
  "gpu_available": "NVIDIA A100-SXM4-40GB",
  "training_time": 20.878034114837646,
  "final_loss": 0.5509733207642086,
  "trainable_parameters": 9011200,
  "total_parameters": 1109059584,
  "peak_gpu_memory_gb": 3.378549098968506,
  "samples_per_second": 23.948614953390603
}