{
  "config": {
    "name": "quick_test",
    "description": "Quick test configuration",
    "lora": {
      "r": 8,
      "lora_alpha": 16,
      "lora_dropout": 0.1,
      "target_modules": [
        "q_proj",
        "v_proj"
      ]
    },
    "training": {
      "batch_size": 2,
      "gradient_accumulation_steps": 2,
      "num_epochs": 1,
      "learning_rate": "3e-4",
      "warmup_steps": 10
    },
    "dataset": {
      "name": "yahma/alpaca-cleaned",
      "max_samples": 100
    },
    "use_wandb": false
  },
  "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
  "start_time": "2025-07-04T22:03:03.112116",
  "model_load_time": 2.284233570098877,
  "gpu_available": "NVIDIA A100-SXM4-40GB"
}